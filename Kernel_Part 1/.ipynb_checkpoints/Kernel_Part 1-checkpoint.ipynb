{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 核心课程 \n",
    "## Part 1 Introduction to Natural Language Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section provides an overview of the program and introduces the fundamentals of Natural Language Processing through symbolic manipulation, including text cleaning, normalization, and tokenization. You'll then build a part of speech tagger using hidden Markov models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "项目：<a> Part of Speech Tagging</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview\n",
    "- Welcome to Natural Language Processing\n",
    "- Udacity Support \n",
    "- <a href='#marker_3'>Intro to NLP</a>\n",
    "- <a href='#marker_4'>Text Processing</a>\n",
    "- Spam Classifier with Naive Bayes\n",
    "- Part of Speech Tagging with HMMs\n",
    "- Project: Part of Speech Tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <p id='marker_3'>3. Intro to NLP</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 结构化语言(Structured Languages)：为什么计算机理解我们很难呢？ \n",
    "人类语言的一大缺陷，依赖于你观察方法的特征，是缺乏准确定义的结构。 \n",
    "\n",
    "为了理解困难的原因，我们首先观察更具**结构化的语言**。 \n",
    "\n",
    "例如：    \n",
    "**数学使用一种结构化语言**，当我写出y=2x+5时，我想表达的意思是非常清晰的。  \n",
    "我的意思是变量y与变量x的相关性是 2x+5，**形式逻辑也使用结构语言**。 \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "例如：  \n",
    "考虑表达式父系(x,y)和父系(x,z)得到同层(y,z)，这个语句表明如果x是y的父系且x是z的父系，那么y和z是同层。\n",
    "\n",
    "<img src='./images/part1_001.png' width='70%'/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "你熟悉的结构化语言，是**脚本语言和编程语言**。\n",
    "\n",
    "思考这个SQL语句：\n",
    "> SELECT name, email FROM users WHERE name LIKE A%\n",
    "\n",
    "我们询问数据库 姓名以\"A\"开头，所有用户的姓名和电子邮箱地址。\n",
    "\n",
    "这些语言的设计，要尽可能清晰，适合计算机处理。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 语法Grammar\n",
    "对计算机而言，结构化语言容易分析和理解。   \n",
    "\n",
    "因为它们受到一套严格规则或语法的定义，这是表达语法和算法的标准形式。\n",
    "\n",
    "可以恰当地分析形成后的语句，理解它的确切含义。\n",
    " \n",
    "如果一个语句与既定语法不匹配，通常计算机无法猜测意思，它就会放弃。\n",
    "这样违反语法规则会报告为语法错误。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src='./images/part1_002.png' width='50%'/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 非结构化文本Unstructured Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们用来交流的语言也界定了语法规则，实际上在一些情况下 我们使用**简单的结构化语句**。  \n",
    "\n",
    "不过大部分人类交谈很复杂，**非结构化**。\n",
    "\n",
    "尽管如此，我们似乎非常善于了解彼此，甚至这种模棱两可在某种程度上受到欢迎。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**那么计算机如何理解非结构化文本呢？**\n",
    "\n",
    "这是一些基本的想法。\n",
    "计算机可以在一定程度上处理词语和短语，试图找出\n",
    "- **关键词**\n",
    "- **词性**\n",
    "- **命名实体**\n",
    "- **日期和数量**等。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src='./images/part1_003.png' width='30%'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用这些信息他们也可以分析语句，至少有一项相对比较结构化，这可以帮助提取语句,问题和指令的相关部分。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从更高级来说，计算机可以\n",
    "- 分析文件\n",
    "- 找出常见词和罕见词\n",
    "- 评估所表达的整体语气或情感\n",
    "- 甚至可以对相似文件进行分类或分组"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./images/part1_004.png' width='30%'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "你可以想象根据上面这些观点，计算机可以对非结构文本进行进行各种事情，即使它们并不像我们一样理解文本。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4 词汇计数Counting Words\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "计算词汇频次Counting Word Frequencies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> As I was waiting, a man came out of a side room, and at a glance I was sure he must be Long John. His left leg was cut off close by the hip, and under the left shoulder he carried a crutch, which he managed with wonderful dexterity, hopping about upon it like a bird. He was very tall and strong, with a face as big as a ham—plain and pale, but intelligent and smiling. Indeed, he seemed in the most cheerful spirits, whistling as he moved about among the tables, with a merry word or a slap on the shoulder for the more favoured of his guests.\n",
    "\n",
    "— Excerpt from Treasure Island, by Robert Louis Stevenson.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following coding exercise, we have provided code to load the text from a file, call the function count_words() to obtain word counts (which you need to implement), and print the 10 most common and least common unique words.\n",
    "\n",
    "Complete the portions marked as TODO to count how many times each unique word occurs in the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Count words.'''\n",
    "import re\n",
    "\n",
    "def count_words(text):\n",
    "    '''Counting how many times each unique word occurs in text.'''\n",
    "    counts = dict() # dictionary of {<word> : <count>} pairs to return\n",
    "    \n",
    "    # TODO: Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # TODO: Split text into tokens (words), leaving out punctuation \n",
    "    # (Hint: Use regex to split on non-alphanumeric characters)\n",
    "    regex = re.compile(r'\\b\\w+\\b')\n",
    "    words = regex.findall(text)\n",
    "    for x in set(words):\n",
    "        counts[x] = words.count(x)\n",
    "    \n",
    "    # TODO: Aggregate word counts using a dictionary\n",
    "    \n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_run():\n",
    "    with open('./files/input.txt', 'r') as f:\n",
    "        text = f.read()\n",
    "        counts = count_words(text)\n",
    "        sorted_counts = sorted(counts.items(), key=lambda pair: pair[1], reverse=True)\n",
    "        \n",
    "        print('10 most common words: \\nWord\\t Count')\n",
    "        for word, count in sorted_counts[:10]:\n",
    "            print('{} \\t {}'.format(word, count))\n",
    "            \n",
    "        print('\\n 10 least common words: \\nWord\\t Count')\n",
    "        for word, count in sorted_counts[-10:]:\n",
    "            print('{} \\t {}'.format(word, count))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 most common words: \n",
      "Word\t Count\n",
      "a \t 9\n",
      "the \t 6\n",
      "he \t 6\n",
      "and \t 5\n",
      "as \t 4\n",
      "was \t 4\n",
      "with \t 3\n",
      "i \t 2\n",
      "his \t 2\n",
      "shoulder \t 2\n",
      "\n",
      " 10 least common words: \n",
      "Word\t Count\n",
      "managed \t 1\n",
      "be \t 1\n",
      "waiting \t 1\n",
      "ham \t 1\n",
      "by \t 1\n",
      "tables \t 1\n",
      "side \t 1\n",
      "whistling \t 1\n",
      "big \t 1\n",
      "tall \t 1\n"
     ]
    }
   ],
   "source": [
    "test_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 注意：字典按value值进行排序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = {'a': 9, 'cut': 1, 'carried': 1, 'hip': 1, 'it': 1, 'merry': 1, 'man': 1, 'at': 1, 'pale': 1, 'bird': 1, 'which': 1, 'room': 1, 'indeed': 1, 'in': 1, 'must': 1, 'for': 1, 'among': 1, 'intelligent': 1, 'spirits': 1, 'face': 1, 'the': 6, 'guests': 1, 'i': 2, 'smiling': 1, 'leg': 1, 'close': 1, 'most': 1, 'his': 2, 'off': 1, 'he': 6, 'dexterity': 1, 'with': 3, 'but': 1, 'on': 1, 'cheerful': 1, 'shoulder': 2, 'word': 1, 'and': 5, 'came': 1, 'crutch': 1, 'favoured': 1, 'out': 1, 'about': 2, 'glance': 1, 'like': 1, 'seemed': 1, 'slap': 1, 'very': 1, 'under': 1, 'moved': 1, 'as': 4, 'upon': 1, 'strong': 1, 'of': 2, 'or': 1, 'plain': 1, 'left': 2, 'more': 1, 'wonderful': 1, 'john': 1, 'was': 4, 'long': 1, 'hopping': 1, 'sure': 1, 'managed': 1, 'be': 1, 'waiting': 1, 'ham': 1, 'by': 1, 'tables': 1, 'side': 1, 'whistling': 1, 'big': 1, 'tall': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', 9), ('the', 6), ('he', 6), ('and', 5), ('as', 4)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_counts = sorted(counts.items(), key=lambda pair:pair[1], reverse=True)\n",
    "sorted_counts[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5 Context Is Everything"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**那么什么原因使计算机无法像人类一样理解自然语言呢？**\n",
    "\n",
    "部分原因在于我们**语句的差异性和复杂性**。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "思考这个电影评论的片段：\n",
    "> “我受到诱惑看到这些过时陈旧的乐趣和诡计，我被骗了”   \n",
    "I was lured to see this on the  promise of a smart, with slice of old fashion fun and intrigue. I was conned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "虽然最开始是，一些可能正面的词语，结果是非常负面的评论。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对我们来说，这样的语句在某种程度上很有趣，但是电脑在分析它们时，可能会出错。\n",
    "\n",
    "不过让自然语言处理的难度超出你想象，存在越大的挑战。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "观察一下这个语句，\n",
    "> “沙发没法通过门 因为它太窄了 (The sofa didn’t fit through the door because it was too narrow.)”\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "“它” 指代什么？\n",
    "显然 “它” 指代门。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在思考下这句话的变体：\n",
    "> “沙发没法通过门 因为它太宽了 (The sofa didn’t fit through the door because it was too wide.)”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个例子中 “它” 指代什么？\n",
    "这里指沙发。 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "思考一下，为了理解这句话的恰当意思或语义。你暗中运用了对物质世界的理解，宽的东西无法通过窄的东西。\n",
    "\n",
    "你可能之前经历过类似的情况，可以想象一下数不胜数的其他场景，其中一些知识或语境是正确理解表达所必不可少的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.6 自然语言处理Natural Language Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "即使面临目前的挑战，**自然语言处理**也充满前景。\n",
    "\n",
    "为了帮助我们更好理解今天如何运用自然语言处理，我们邀请了 IBM 公司的 Armen Pischdotchian，目前担任学术科技导师。\n",
    "> Armen：我使用 Watson 认知服务，为大学、高中、STEM 专业和女程序员进行讲课， 组织工作坊，我们也使用 IBM Watson 认知服务运行编程马拉松 (hackathon)。\n",
    "这项服务位于 Bluemix 服务平台上。\n",
    "> 我们做的另一项工作是经常装扮成系统架构师，因为大学也与客户进行合作。这些客户使用学术环境做为开发场地，我非常期待这类拓展式合作。我会竭力为这样的客户构建概念实证。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们已经了解到，越来越多的项目使用不同方式的自然语言处理。\n",
    "如今自然语言处理，并不是单独使用，而是嵌入在智能端对端解决方案的一部分。使用大量各种技术，通常提升认知视野，而不只是纸上谈兵。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**那你认为自然语言处理在这样系统中的主要角色是什么呢？**\n",
    "\n",
    "自然语言处理在计算机科学中是一大难题。   \n",
    "人类语言几乎不准确，无法清晰表达。   \n",
    "理解人类语言，不仅是要理解词汇，还要理解概念以及如何组合在一起形成意思。    \n",
    "虽然对人类来说语言是很容易学习的，但是语言的模糊性导致，计算机难以掌握自然语言处理。   \n",
    "\n",
    "例如思考这个短语：\n",
    "> 这个喷泉不是饮用水 (this fountain is not drinking water)\n",
    "\n",
    "认知系统可以对词组拆分字段，分析并添加注释，推断出喷泉与喝水行为无关。   \n",
    "不过我们知道，这是说我们不应该从这个喷泉中喝水。   \n",
    "如今的系统不仅可以分析话语，它们理解词语之间的联系，话语前后的语境。    \n",
    "\n",
    "例如：\n",
    "> 我可以更好地用语言描述自己的需求时，为什么需要浏览几十个Airbn评论，找到合适的住宿呢？\n",
    "\n",
    "我要寻找一个可以看到河流的公寓，可以俯瞰曼哈顿，但我不想要嘈杂和脏臭的位置。  我希望认知系统可以找到，顾客的评论，准确描述我要找的标准。\n",
    "\n",
    "\n",
    "因此自然语言处理派上用场，它可以\n",
    "- 帮助理解用户的意图，\n",
    "- 了解他们的喜恶，\n",
    "- 处理大量文本，\n",
    "- 来更好地推断我们对话的语境，\n",
    "- 和我们所表达的准确含义。 \n",
    "\n",
    "\n",
    "例子：\n",
    "> 聪明人与聪明的家伙肯定不相同 (A wise man is absolutely not the\n",
    "same as a wise guy)\n",
    "\n",
    "> 机会渺茫相当于机会很小 (a slim chance is the same as a\n",
    "fat chance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.7 Applications of NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "你刚才提到与大学和相关客户合作，**构建认知解决方案，解决他们棘手的问题，\n",
    "你可以给我们介绍这些项目中自然语言处理发挥关键作用的示例吗？**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 我印象深刻的一次合作是在纽约市的圣约翰大学，准确说应该是教师学院，听众包括教师、实践导师、人生导师、C语言导师等。  \n",
    "他们都是主题专家，他们寻找**衡量如何高效的标准，让教导学徒导师成为专家，独立承担任务。**  \n",
    "我建议我们录制教师与学徒之间的面试，让硕士生学习训练，**语音到文本SPEECH TO TEXT 是这里第一个认知服务**，这可以理解双方的话语； 然后我们运行**音调分析器TONE ANALYZER 和情感分析SENTIMENT ANALYSIS **，通过高亮语句进一步揭露学生表现出来的开放性、责任感、外向性、亲和性和情绪不稳定性。\n",
    "你可以联机改变语句，观察颜色代码的变化。\n",
    "顺便说一下，心理学家在分析文本中使用五大人格特点，对每个话语返回**置信度**。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 这是另一个例子 Watson 肿瘤解决方案 (Watson for Oncology) 帮助外科医生，\n",
    "迅速确认患者病例中的关键信息，调查相关文章，并且探索，减少多余护理变化的治疗选择，然后把时间反馈给他们的病人。\n",
    "\n",
    "\n",
    "> 印度班加罗尔的马尼帕尔医院，对 Watson 进行试点，对比基于Watson 肿瘤解决方案的建议和马尼帕尔医院肿瘤团队的建议。\n",
    "这是个 12 到 15 名癌症专家组成的团队，每周审查最复杂的癌症案例，在**双盲法研究**中 马尼帕尔的医生发现 Watson和肿瘤团队对 90% 乳腺癌案例的建议是一致的，这项研究发表在圣安东尼奥乳腺癌研讨会上。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**自然语言处理还有没有其他形式融入到日常产品和服务中呢？**\n",
    "\n",
    "这样来思考，首先以前的网站，然后应用程序，现在的机器人程序，我们来思考形式上的三个转变，其中自然语言处理改变了我们对周围世界的认知和行为。\n",
    "- 首先是一对一和一对多。  \n",
    "    - 第一次出现在广告营销历史中，品牌有机会从个人角度接触到消费者，以消费者口述出来的速度进行传播。\n",
    "在对话式世界中营销人员不再依靠叫卖获得最好的结果，他们需要聊天和聆听。\n",
    "\n",
    "- 第二是小数据和大数据\n",
    "    - 这种一对一的交流可以给你提供个人见解和特性，提供简单易懂可行的数据，它第一次以人类自然语境的方式，建立了信息排序的完美平台。\n",
    "\n",
    "- 第三 永远在线和永远完美\n",
    "    - 真实和原始的崛起，Periscope 和 Snapchat 等直播应用程序，代表了千禧一代和 Z 一代青少年依赖的最新社交货币，所以永远在线，保持真实。\n",
    "对一个品牌更重要，而不是完美的图像或像素。\n",
    "那样只会偶尔在线，永远迟到。每个对话都记录成日志，这样你可以保持追踪，重复，经过一段时间提升你的机器人程序质量。\n",
    "\n",
    "\n",
    "同样，你在手机或汽车上使用的语音界面，它们应用了自然语言处理，理解你所说的内容，这是因为语音是极具噪音来源的输入。\n",
    "\n",
    "如果没有智能，很难处理。去年 IBM 在对话式语音识别方面宣布了一项重大里程碑。\n",
    "这个系统实现了 6.9% 词语错误率。\n",
    "\n",
    "此后我们继续推动语音识别的边界，今天我们已经实现了 5.5% 词语错误率，打破业界记录。\n",
    "\n",
    "这是通过极其困难的语音识别任务衡量的，记录人们日常话题的讨论对话 ，例如买车。\n",
    "录音后的语料库就是 Switchboard，在过去二十年中这成为语音识别系统的标准检查程序，我们实现了突破5.5% 成为巨大突破。\n",
    "\n",
    "相较于人类词语错误率是 5.1%，这表明我们找到了合适的方法，然后可以认为语音识别技术能够和人类媲美。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**自然语言处理中需要解决最重要的挑战是什么呢？**\n",
    "\n",
    "最大的挑战是**理解和维持对话中的语境**。\n",
    "当你和某人说话时，通常会持续一个以上的话语和响应，进行对话时，你开始构建正在讨论内容的心智模型，这可以提供正确理解接下来内容的更多语境。\n",
    "\n",
    "我们使用心理捷径，心理学家把这称为启发式偏差。\n",
    "\n",
    "我认为现在还没有攻克这个问题。\n",
    "这严重限制了今天自然语言处理系统的能力。\n",
    "\n",
    "这不仅适用于对话，如果你不知道提取机制，使用事实和其中体现的关系，处理文章或报道等大量文本变得很难。\n",
    "\n",
    "系统缺乏的是经验——对世界的整体了解。\n",
    "\n",
    "不过这是活跃的研究领域，所以我希望未来看到巨大进步，这很有前景。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**还有没有其他人工智能工程师和研究人员正在解决的自然语言处理问题呢？**\n",
    "\n",
    "这让我想到深度学习的进步，作为机器学习的一部分，人们已经意识到的东西和即将到来的事物形态。\n",
    "\n",
    "让我来回顾一下，Pedro Domingos 在他的《主算法 (The Master Algorithm)》书中指出了人工智能的三大分类，\n",
    "- 弱人工智能 ANI - Artificial Narrow Intelligence\n",
    "- 通用人工智能 AGI - Artificial General Intelligence\n",
    "- 超人工智能 ASI - Artificial Super Intelligence\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 弱人工智能 ANI\n",
    "\n",
    "今天我们拥有弱人工智能 (ANI)，有时候也表示弱人工智能，弱人工智能是指擅长单一领域的人工智能。\n",
    "它可以打败 《危险边缘》 的世界冠军，询问它找到在硬盘存储数据更好的方法，也会茫然若失地看着你。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 第二是通用人工智能 (AGI)   \n",
    "\n",
    "有时候也表示强人工智能或人类级别的人工智能。通用人工智能是指，计算机在各方面都像人类一样聪明，机器可以像人类一样执行任何智能任务。\n",
    "\n",
    "我来举个例子，卡耐基梅隆大学向通用人工智能迈出的一小步，当你走近卡耐基梅隆大学大厅时，会受到一个机器人的欢迎，不是人类形状，不过它有支架支撑的车轮和屏幕，我让机器人引导我去约翰的办公室，机器人具有面部识别 API，我登记后，它会说 “你好，Armen？很好，跟我走吧！”，在走廊行走时，屏幕会告诉我 20 英尺后我们向左转，15 英尺后向右转，我们到达约翰的办公室后站立的地点会变成绿色，经过电梯时，有人踢了机器人前面的椅子，机器人看到后阻止了，来回走动，我也是这样。到达约翰的办公室后，约翰问机器人两个很难的问题：“坐电梯时发生了什么？ 你为什么迟到了？”机器人了解自己的环境，不是自身，而是自己的环境。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 第三是超人工智能 (ASI)\n",
    "\n",
    "牛津哲学家和人工智能知名思想家Nick Bastar 把超人工智能定义为：\n",
    "**所有领域都比最优秀的人类大脑都聪明，包括科学创新、通识和社交技能。**\n",
    "\n",
    "超人工智能从计算机只比人类聪明一点，到各方面都聪明几万亿倍。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "今天我向最高级的深度学习提出一个问题。\n",
    "\n",
    "> “Watson 告诉我量子计算的知识吧？\"\n",
    "\n",
    "它可能会说 “Armen，我不知道量子计算，你可以教教我”。\n",
    "然后我就会在系统中加入相关文件，这会成为它语料库的一部分。\n",
    "不过机器的回答会完全不同 “Armen，我知道自己不了解量子计算，你可以教教我”。\n",
    "\n",
    "通过超人工智能，系统更了解自己。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**听起来超人工智能是大多数人期待的自动系统，但是我们显然还有一些困难，研究人员如何克服这些困难挑战呢？深度学习如何应用到自然语言处理中呢？**\n",
    "\n",
    "自然语言处理植根于计算语言学研究人员使用基于规则的系统解决问题，不过由于内在的复杂性，自然语言缺少结构，深度学习方法可以用来解决**情感分析和消除歧义**等问题。\n",
    "\n",
    "需要解决一些相关挑战：\n",
    "- 例如怎样把文本转化成适合学习的表示呢？\n",
    "- 如何解读这种系统的输出呢？\n",
    "\n",
    "我认为秘诀是算法，现在我们的开发人员正在利用 LSTM 进行试验，即长短期记忆，这是神经网络解决此类问题的现代方法。\n",
    "\n",
    "图像描述Image Captioning和视觉问答Visual Question-Answering，也是目前非常热门的研究话题。  \n",
    "综合了形态、图像和文本，深度学习方法使用常见的潜在向量表示解决这些问题，它们的应用取得了巨大成功，除了语言处理 这些系统可能成为更多通用目的人工智能系统的先驱。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.8 NLP and Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "自然语言处理 (NLP) 是世界上发展最快的领域之一。\n",
    "NLP 已经发展到我们日常使用的多种产品和服务中。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们首先简单介绍一下如何设计 端对端 NLP 管道？\n",
    "> How to design an end-to-end NLP pipeline?\n",
    "\n",
    "不是那种管道，而是自然语言处理管道。从任何可用形式的**原始文本开始**，对它进行处理，提取相关特征，建立模型，从而完成各种 NLP 任务。\n",
    "\n",
    "仔细想想，这有点像原油精炼。\n",
    "\n",
    "你将学习\n",
    "- 这些不同管道阶段如何互相依赖\n",
    "- 还将学习如何做出设计决策\n",
    "- 如何选择现有库以及工具从而进行每个步骤的操作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.9 How NLP Pipelines Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们看一个常见的自然语言处理 (NLP) 管道，它由三个阶段组成：\n",
    "- 文本处理  Text Processing\n",
    "- 特征提取  Feature Extraction\n",
    "- 建模 Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "每个阶段以特定方式转换文本，生成下一阶段所需的结果。\n",
    "\n",
    "例如：    \n",
    "文本处理的目标是获取原始输入文本，清洗、标准化，然后将其转换成适合进行特征提取的形式。\n",
    "\n",
    "同样，下一阶段需要提取和生成适用于你计划使用的模型类型，和你尝试完成的 NLP 任务的**特征表示法**。\n",
    "\n",
    "在建立这种管道时，工作流程可能不是完全线性的，假设你花费了一些时间实现文本处理功能，然后建立了几个简单的特征提取器，然后设计了一个基准统计模型。\n",
    "但是，你可能对结果并不满意。\n",
    "\n",
    "所以你回去重新思考需要哪些特征，这样，就可以更改你的处理路径，请记住：这是一个非常简单的自然语言处理介绍，实际应用中需要更多步骤。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./images/part1_005.png' width='70%'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.8 Text Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们现在详细介绍文本处理，我们想到的第一个问题是：\n",
    "**为什么要处理文本？为什么不能直接输入？**\n",
    "\n",
    "要理解这一点，请思考一下我们先从哪里获取这个文本。 \n",
    "<img src='./images/part1_006.png' width='60%'/>\n",
    "**网站**是文本信息的常见来源，这是维基百科一个网页样本的一部分以及对应的 HTML 标记。\n",
    "\n",
    "HTML 标记就是我们的原始输入，为了进行自然语言处理，一般需要清除所有或者大部分 HTML 标记，仅保留纯文本。还可以清除或者提取任何 URL 或者与你的任务无关的其它项目。\n",
    "\n",
    "Web 可能是最常见、发展最快的文本内容来源。  \n",
    "但还可能需要使用 PDF，Word 文件或其它文件格式，或者原始输入可能来自语音识别系统或者 OCR 书本扫描文件。\n",
    "了解源媒体有助于正确处理输入，最终目标是**提取不含任何来源标记的纯文本**。\n",
    "<img src='./images/part1_007.png' width='60%'/>\n",
    "\n",
    "\n",
    "\n",
    "或与任务无关的结构，获取纯文本之后，可能需要进一步处理。\n",
    "\n",
    "例如：  \n",
    "大写一般不会改变词的含义，我们可以把所有词全部转换成大写/小写，确保以相同的方式对其进行处理。\n",
    "<img src='./images/part1_009.png' width='60%'/>\n",
    "\n",
    "还可以清除用于表示停顿等的标点符号，一个语言中的某些常用词通常能提供结构。\n",
    "<img src='./images/part1_010.png' width='60%'/>\n",
    "\n",
    "但不会包含太多含义，例如 “一个”、“和”、“的”、“是” 等，有时，如果有助于降低后续程序的复杂度，最好将其清除。\n",
    "<img src='./images/part1_008.png' width='60%'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.9 Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**我们现在得到标准化纯文本，我们可以把它输入统计模型或机器学习模型吗？**\n",
    "\n",
    "不可以。\n",
    "\n",
    "我们看一下为什么。\n",
    "<img src='./images/part1_011.png' width='30%'/>\n",
    "文本数据是利用ASCII 或 Unicode 等编码，将每个字符映射到一个数字而显示在现代计算机上，计算机存储这些值并以二进制形式（零和一）传输。\n",
    "\n",
    "**这些数字还有隐含的顺序，65 小于 66 而 66 小于 67，这是否意味着 A 小于 B，B 小于 C？**  \n",
    "\n",
    "不是。实际上，这是一个错误假设，可能会误导自然语言处理算法。    \n",
    "另外，单个字符本身没有太多含义。    \n",
    "我们关注的应该是**词**，但是计算机并没有针对词的标准表示法。\n",
    "从内部来看，它们只是 ASCII 或 Unicode 值的序列，并没有捕捉词的含义或关系。\n",
    "\n",
    "<img src='./images/part1_012.png' width='30%'/>\n",
    "\n",
    "\n",
    "将这种情况与计算机内存中的图像表示法相比较。\n",
    "\n",
    "每个像素值包含图像中这个点的相对光强。对于彩色图像来说，每个原色，红、绿、蓝都有一个值，这些值包含相关信息，值相似的两个像素在视觉上是相似的。因此，可以直接在值模型中使用像素值。可能还需要一些进行特征工程，例如边缘检测或过滤，但是像素是一个很好的开始。\n",
    "<img src='./images/part1_013.png' width='30%'/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./images/part1_014.png' width='30%'/>\n",
    "所以，问题在于**对于可以用作建模特征的文本数据，如何想出一个相似的表示法？**\n",
    "\n",
    "\n",
    "答案取决于你使用的是哪种类型的模型，以及你想完成什么任务。     \n",
    "- 如果你想使用基于图形的模型提取洞察信息，你可能想用包含其相互关系的符号节点，如：**WordNet 表示词**。\n",
    "<img src='./images/part1_015.png' width='40%'/>\n",
    "\n",
    "- 但是，对于统计模型，你需要使用某种**值表示法**。\n",
    "<img src='./images/part1_016.png' width='60%'/>\n",
    "\n",
    "但你仍然需要思考最终目标是什么？\n",
    "- 如果你想进行文档级任务，例如：垃圾邮件检测或情感分析，你可能想用**文档表示法**。例如：**词袋** 或 **doc2vec**。\n",
    "\n",
    "- 如果你想处理单个词和短语，例如：用于文本生成或机器翻译，你需要用**词级表示法**。例如：**word2vec** 或**glove**。\n",
    "\n",
    "文本信息有多种表示方法，只有通过实践，才能明白应该使用哪种方法解决每个问题。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WordNet visualization tool: http://mateogianolio.com/wordnet-visualization/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.10 Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个过程的最后一个阶段，我称之为建模。\n",
    "\n",
    "这一过程包括\n",
    "- 模型设计\n",
    "一般指**统计模型**或**机器学习模型**，利用优化程序将其参数拟合到训练数据，然后用它对未知数据进行预测。\n",
    "\n",
    "处理值特征的优势在于，几乎可以使用任何机器学习模型，包括支持向量机、决策树、神经网络或你选择的任何自定义模型，甚至可以组合多个模型以获得更好的性能。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如何使用模型则取决于你。\n",
    "- 你可以将它部署为基于网络的应用\n",
    "- 将其包装成方便的移动应用\n",
    "- 与其它产品服务等集成，有各种可能。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <p id='marker_4'>4. Text Processing</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Text Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "在这一节课，你将学习如何**从不同来源读取文本数据**以及**如何准备文本数据进行特征提取**。\n",
    "- 首先对其进行清洗，清除无关项目。\n",
    "例如：HTML 标签\n",
    "- 然后将文本统一转换成小写，清除标点符号和多余空格，使其标准化。\n",
    "- 将文本分拆成**词**或令牌，清除过于常见的词，也就是停止词\n",
    "- 最后，你将学习如何识别不同的语音部分，命名实体，并通过**词干提取和词形还原**将词转换成规范形式\n",
    "\n",
    "完成所有这些处理步骤之后，文本可能会有很大变化，但以更易处理的形式，保留了表达内容的本质。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Coding Exericises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href='./Exercises/*/text_processing.ipynb'>详细的项目操作内容见当下目录Exercises:</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Introduction to GPU Workspaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4 Workspaces: Best Practices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5 Workspaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.6 Capturing Text Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.7 Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.8 Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.9 Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.10 Stop Word Removal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.11 Part-of-Speech Tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.12 Named Entity Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.13 Stemming and Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.14 Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
